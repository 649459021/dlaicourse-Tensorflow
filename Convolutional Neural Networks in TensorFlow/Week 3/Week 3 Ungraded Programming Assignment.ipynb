{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8bb33a0-d5c9-4849-ae91-8ef1ab1c05a2"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150,150,3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "  # Your Code Here\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-01 10:50:54--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.161.80, 2404:6800:4004:81a::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.161.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep   4%[                    ]   4.01M  18.0MB/s               \r        /tmp/incept  38%[======>             ]  32.01M  68.2MB/s               \r       /tmp/incepti  80%[===============>    ]  67.17M   100MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   115MB/s    in 0.7s    \n",
            "\n",
            "2019-09-01 10:50:55 (115 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0901 10:50:57.314554 140113070475136 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e00db33-f612-42cc-d918-4b0a2c952191"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9eb6129f-0188-4681-e9b8-10b7cdf52f03"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024,activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.4)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1,activation = tf.nn.sigmoid)(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0378461c-4f5d-403f-848e-2c13e481c4ca"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-01 10:55:12--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.197.176, 2404:6800:4004:80b::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.197.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  76.7MB/s    in 1.9s    \n",
            "\n",
            "2019-09-01 10:55:14 (76.7 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-09-01 10:55:16--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.161.80, 2404:6800:4004:819::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.161.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-09-01 10:55:17 (142 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "52153995-4b7d-4e00-bcbd-110e8858092b"
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses'\n",
        "train_humans_dir = '/tmp/training/humans'\n",
        "validation_horses_dir = '/tmp/validation/horses'\n",
        "validation_humans_dir = '/tmp/validation/humans'\n",
        "\n",
        "train_horses_fnames = os.listdir('/tmp/training/horses')\n",
        "train_humans_fnames = os.listdir('/tmp/training/humans')\n",
        "validation_horses_fnames = os.listdir('/tmp/validation/horses')\n",
        "validation_humans_fnames = os.listdir('/tmp/validation/humans')\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8b665293-4e4a-4b4b-f9ff-831d1528342e"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,batch_size = 20,target_size = (150,150),class_mode = 'binary')     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,batch_size = 20,target_size = (150,150),class_mode = 'binary')\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66bf7637-7076-4a0c-e5de-e3f3491e2c36"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch = 20,\n",
        "                              epochs = 100,\n",
        "                              callbacks = [callbacks],\n",
        "                              validation_data = validation_generator,\n",
        "                              validation_steps = 50,\n",
        "                              )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 10s 479ms/step - loss: 0.5650 - acc: 0.7775 - val_loss: 0.0249 - val_acc: 0.9960\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.1579 - acc: 0.9475 - val_loss: 0.0247 - val_acc: 0.9889\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.1314 - acc: 0.9483 - val_loss: 0.0201 - val_acc: 0.9919\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 6s 316ms/step - loss: 0.1816 - acc: 0.9175 - val_loss: 0.0246 - val_acc: 0.9889\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 6s 282ms/step - loss: 0.1544 - acc: 0.9612 - val_loss: 0.0052 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 7s 373ms/step - loss: 0.0750 - acc: 0.9819 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 6s 315ms/step - loss: 0.0456 - acc: 0.9875 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 6s 319ms/step - loss: 0.0801 - acc: 0.9700 - val_loss: 0.0140 - val_acc: 0.9960\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.0509 - acc: 0.9871 - val_loss: 0.0055 - val_acc: 0.9970\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 6s 299ms/step - loss: 0.0423 - acc: 0.9900 - val_loss: 0.0032 - val_acc: 1.0000\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 7s 347ms/step - loss: 0.0533 - acc: 0.9825 - val_loss: 0.0083 - val_acc: 0.9960\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 6s 307ms/step - loss: 0.0246 - acc: 0.9925 - val_loss: 0.0021 - val_acc: 1.0000\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0541 - acc: 0.9897 - val_loss: 0.0056 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0313 - acc: 0.9850 - val_loss: 7.5353e-04 - val_acc: 1.0000\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 6s 316ms/step - loss: 0.0291 - acc: 0.9900 - val_loss: 0.0568 - val_acc: 0.9808\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 6s 315ms/step - loss: 0.0388 - acc: 0.9922 - val_loss: 0.0127 - val_acc: 0.9960\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.0542 - acc: 0.9793 - val_loss: 0.0265 - val_acc: 0.9970\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 6s 277ms/step - loss: 0.0513 - acc: 0.9875 - val_loss: 0.0173 - val_acc: 0.9960\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 8s 383ms/step - loss: 0.0449 - acc: 0.9850 - val_loss: 0.0069 - val_acc: 0.9960\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 6s 315ms/step - loss: 0.0391 - acc: 0.9871 - val_loss: 0.0526 - val_acc: 0.9798\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 6s 317ms/step - loss: 0.0228 - acc: 0.9875 - val_loss: 0.0025 - val_acc: 0.9970\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 6s 313ms/step - loss: 0.0321 - acc: 0.9897 - val_loss: 0.2939 - val_acc: 0.9585\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 6s 299ms/step - loss: 0.0328 - acc: 0.9875 - val_loss: 0.0030 - val_acc: 0.9960\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 7s 345ms/step - loss: 0.0372 - acc: 0.9850 - val_loss: 7.5545e-04 - val_acc: 1.0000\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0073 - val_acc: 0.9960\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.0869 - acc: 0.9775 - val_loss: 0.1492 - val_acc: 0.9656\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 6s 313ms/step - loss: 0.0745 - acc: 0.9725 - val_loss: 0.0603 - val_acc: 0.9879\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0167 - acc: 0.9922 - val_loss: 0.0608 - val_acc: 0.9848\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0664 - acc: 0.9875 - val_loss: 0.0137 - val_acc: 0.9960\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 6s 308ms/step - loss: 0.0375 - acc: 0.9948 - val_loss: 0.0823 - val_acc: 0.9838\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 6s 277ms/step - loss: 0.0306 - acc: 0.9875 - val_loss: 0.0887 - val_acc: 0.9798\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 8s 380ms/step - loss: 0.0355 - acc: 0.9825 - val_loss: 0.3945 - val_acc: 0.9555\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 6s 315ms/step - loss: 0.0405 - acc: 0.9850 - val_loss: 2.8447e-04 - val_acc: 1.0000\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.0272 - acc: 0.9845 - val_loss: 0.0585 - val_acc: 0.9879\n",
            "Epoch 35/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0044 - acc: 1.0000\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "3d957e4b-bdc1-4c96-8654-f98aadc84ce2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYUQRJvqGYRhRxP8Dtz8v8FaZXoMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrptC6Nth1of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}